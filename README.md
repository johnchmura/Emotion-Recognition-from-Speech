Thought for a couple of seconds

<!-- README.md -->

# Speech Emotion & Vocalâ€‘Channel Recognition

A Python toolkit for training and evaluating **Hidden Markov Models** (HMMs) on speech data to perform:

- **Emotion Recognition** (neutral, calm, happy, sad, angry, fearful, disgust, surprised)  
- **Vocalâ€‘Channel Classification** (speech vs. song)

This package provides endâ€‘toâ€‘end data parsing, preprocessing, feature extraction, model training, and evaluation via a simple Commandâ€‘Line Interface (`ser`).

---

## ğŸ“¦ Installation

1. **Clone the repository**  
   ```bash
   git clone https://github.com/yourâ€‘org/speech_emotion_recognition.git
   cd speech_emotion_recognition
   ```

2. **Create & activate a virtual environment**  
   ```bash
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install dependencies in editable mode**  
   ```bash
   pip install --upgrade pip setuptools wheel
   pip install -e .
   ```

---

## âš™ï¸ Configuration

All paths and hyperparameters live in `config.toml` at the project root:

```toml
[paths]
raw_data_dir     = "data/Audio_Speech_Actors_01-24"
preproc_dir      = "data/preprocessed"
cleaned_csv      = "data/cleaned_data.csv"
models_dir       = "models"

[mfcc]
sr        = 16000
n_mfcc    = 13
frame_len = 0.025
hop_len   = 0.010
n_mels    = 40

[hmm]
n_states = 5
n_iter   = 30
```

Feel free to tweak sampling rate, MFCC settings, or HMM states and iterations.

---

## ğŸš€ Usage

After installation, you have a single CLI entrypoint:  

```bash
$ ser --help
```

### 1. Preprocess

Parse raw RAVDESS filenames into a metadata CSV and resample + normalize all WAVs:

```bash
ser preprocess
```

- **Output**:  
  - `data/cleaned_data.csv` (one row per utterance with parsed fields)  
  - `data/preprocessed/...` (mono 16â€¯kHz, preâ€‘emphasized, normalized WAVs)

### 2. Train

Train HMMs in one of two modes:

```bash
# Emotion models (one HMM per emotion)
ser train --mode emotion

# Vocalâ€‘channel models (one HMM per channel: speech vs. song)
ser train --mode vocal
```

Trained model files will be saved under:

```
models/
â”œâ”€â”€ emotion/
â”‚   â”œâ”€â”€ angry.pkl
â”‚   â”œâ”€â”€ calm.pkl
â”‚   â””â”€â”€ â€¦ 
â””â”€â”€ vocal/
    â”œâ”€â”€ speech.pkl
    â””â”€â”€ song.pkl
```

### 3. Evaluate

Evaluate heldâ€‘out performance and plot a confusion matrix:

```bash
# Emotion recognition evaluation
ser eval --mode emotion

# Vocal-channel evaluation
ser eval --mode vocal
```

---

## ğŸ” Model Methodology

1. **Filename Parsing**  
   - RAVDESS filenames (e.g. `03-01-06-02-02-02-15.wav`) are split into fields:  
     modality, vocal channel, emotion, intensity, statement, repetition, actor  
   - Stored in `data/cleaned_data.csv`.

2. **Preprocessing**  
   - **Mono conversion**, **DCâ€‘offset removal**, **preâ€‘emphasis** (Î±=0.97)  
   - **Resampling** to 16â€¯kHz, **peak normalization**  
   - Silence trimming is optional (controlled in code).

3. **Feature Extraction**  
   - **MFCCs** (13 coefficients) computed on 25â€¯ms frames with 10â€¯ms hop  
   - **Deltas** & **deltaâ€‘deltas** stacked â†’ 3Ã—13 features per frame  
   - **Cepstral Meanâ€“Variance Normalization** per utterance

4. **Hidden Markov Models**  
   - One **GaussianHMM** (diagonal covariance) per class  
   - Trained with **EM** for a fixed number of states (configurable)  
   - **Emotion HMMs** use a stratified train/test split by emotion  
   - **Vocal HMMs** use a leaveâ€‘actorsâ€‘out scheme for robust generalization  

5. **Evaluation**  
   - Logâ€‘likelihood scoring on test sequences  
   - **Confusion matrix** and **overall accuracy** metrics  

---

## ğŸ“‚ Project Structure

```
speech_emotion_recognition/
â”œâ”€â”€ setup.py                 # setuptools install script
â”œâ”€â”€ config.toml              # project & model configuration
â”œâ”€â”€ src/
â”‚   â””â”€â”€ speech_emotion_recognition/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ ser.py           # CLI entrypoint
â”‚       â”œâ”€â”€ data_parser.py   # filename â†’ metadata
â”‚       â”œâ”€â”€ feature_extraction.py  # audio preprocess
â”‚       â”œâ”€â”€ train.py         # train_emotion_hmms & train_vocal_hmms
â”‚       â””â”€â”€ evaluate.py      # evaluate_emotion_hmms & evaluate_vocal_hmms
â””â”€â”€ data/                    # raw & preprocessed data (not committed)
```

---

## ğŸ§ª Testing

Use pytest for unit tests:

```bash
pip install pytest
pytest
```

---

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.